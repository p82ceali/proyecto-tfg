# tools/model_training_tool.py
from __future__ import annotations
from enum import Enum
from typing import Any, Dict, Optional, Type, Tuple

import os
import json
import joblib
import numpy as np
import pandas as pd
from pydantic import BaseModel, Field, field_validator
from crewai.tools import BaseTool

from shared_context import CTX

# --------------------------------------------------------------------------------------
# Helpers
# --------------------------------------------------------------------------------------

def _get_df(tool: BaseTool) -> pd.DataFrame:
    df = getattr(tool, "dataset", None)
    if df is None:
        raise ValueError("No dataset assigned to tool. Set `tool.dataset = your_dataframe` before running.")
    if not isinstance(df, pd.DataFrame):
        raise TypeError("`dataset` must be a pandas DataFrame.")
    return df


def _get_features_target(df: pd.DataFrame, target: Optional[str]) -> Tuple[pd.DataFrame, pd.Series, str]:
    if target is None:
        # Heuristic: use the last column if not specified
        target = df.columns[-1]
    if target not in df.columns:
        raise ValueError(f"Target column '{target}' not found. Available: {list(df.columns)}")
    X = df.drop(columns=[target])
    y = df[target]
    return X, y, target


def _safe_mkdir(path: str) -> str:
    os.makedirs(path, exist_ok=True)
    return path


def _dump_json(path: str, data: Dict[str, Any]) -> None:
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)


# --------------------------------------------------------------------------------------
# Tool: ModelTrainingTool
# --------------------------------------------------------------------------------------

SUPPORTED_MODELS = [
    "logistic_regression",
    "random_forest",
    "xgboost",
    "svm",
    "linear_regression",
]
class SupportedModels(str, Enum):
    logistic_regression = "logistic_regression"
    random_forest = "random_forest"
    xgboost = "xgboost"
    svm = "svm"
    linear_regression = "linear_regression"

class ModelTrainingInput(BaseModel):
    problem_type: str = Field(..., description="Problem type: classification or regression.")
    target: Optional[str] = Field(None, description="Target column name. If None, the last DataFrame column is used.")
    model: SupportedModels = Field(
        SupportedModels.random_forest,
        description=f"Model to train. Options: {SUPPORTED_MODELS}"
    )
    test_size: float = Field(0.2, ge=0.05, le=0.5, description="Proportion for the test split.")
    random_state: int = Field(42, description="Random seed.")
    n_estimators: Optional[int] = Field(None, description="# trees (RF/XGB)")
    max_depth: Optional[int] = Field(None, description="Max depth (RF/XGB)")
    learning_rate: Optional[float] = Field(None, description="Learning rate (XGB)")
    C: Optional[float] = Field(None, description="C parameter (SVM / LogisticRegression)")
    penalty: Optional[str] = Field(None, description="Penalty for LogisticRegression (l1, l2, elasticnet, none)")
    solver: Optional[str] = Field(None, description="Solver for LogisticRegression")
    artifacts_dir: str = Field("pipeline_data/artifacts", description="Directory to save model and metrics.")
    model_name: Optional[str] = Field(None, description="Base filename for the model. Autogenerated if None.")

    @field_validator("penalty")
    @classmethod
    def _normalize_penalty(cls, v):
        return None if (v is None or str(v).lower() == "none") else v


class ModelTrainingTool(BaseTool):
    name: str = "model_training"
    description: str = (
        "Train a scikit-learn model (or xgboost, if available) for classification or regression. "
        "Performs train/test split, computes metrics, and persists artifacts (model + metrics)."
    )
    args_schema: Type[ModelTrainingInput] = ModelTrainingInput
    # Will be injected externally
    dataset: Type[pd.DataFrame] = None

    def _run(
        self,
        problem_type: str,
        target: Optional[str] = None,
        model: str = "random_forest",
        test_size: float = 0.2,
        random_state: int = 42,
        n_estimators: Optional[int] = None,
        max_depth: Optional[int] = None,
        learning_rate: Optional[float] = None,
        C: Optional[float] = None,
        penalty: Optional[str] = None,
        solver: Optional[str] = None,
        artifacts_dir: str = "pipeline_data/artifacts",
        model_name: Optional[str] = None,
    ) -> str:
        try:
            from sklearn.model_selection import train_test_split
            from sklearn.metrics import (
                accuracy_score, f1_score, precision_score, recall_score, roc_auc_score,
                mean_squared_error, r2_score, mean_absolute_error
            )

            df = _get_df(self)
            X, y, target_col = _get_features_target(df, target)

            # Split
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state, stratify=y if problem_type == "classification" else None
            )

            # Model factory
            model_obj = None
            model_used = model

            if model == "random_forest":
                if problem_type == "classification":
                    from sklearn.ensemble import RandomForestClassifier
                    model_obj = RandomForestClassifier(
                        n_estimators=n_estimators or 200,
                        max_depth=max_depth,
                        random_state=random_state,
                        n_jobs=-1,
                    )
                else:
                    from sklearn.ensemble import RandomForestRegressor
                    model_obj = RandomForestRegressor(
                        n_estimators=n_estimators or 300,
                        max_depth=max_depth,
                        random_state=random_state,
                        n_jobs=-1,
                    )

            elif model == "logistic_regression":
                if problem_type != "classification":
                    return "LogisticRegression is only applicable to classification problems."
                from sklearn.linear_model import LogisticRegression
                model_obj = LogisticRegression(
                    C=C or 1.0,
                    penalty=penalty or "l2",
                    solver=solver or "lbfgs",
                    max_iter=200,
                )

            elif model == "svm":
                if problem_type != "classification":
                    return "SVM here is configured for classification only."
                from sklearn.svm import SVC
                model_obj = SVC(C=C or 1.0, probability=True, random_state=random_state)

            elif model == "linear_regression":
                if problem_type != "regression":
                    return "LinearRegression is only applicable to regression problems."
                from sklearn.linear_model import LinearRegression
                model_obj = LinearRegression()

            elif model == "xgboost":
                try:
                    import xgboost as xgb
                    if problem_type == "classification":
                        model_obj = xgb.XGBClassifier(
                            n_estimators=n_estimators or 300,
                            max_depth=max_depth or 6,
                            learning_rate=learning_rate or 0.1,
                            subsample=0.9,
                            colsample_bytree=0.9,
                            random_state=random_state,
                            eval_metric="logloss",
                            n_jobs=-1,
                        )
                    else:
                        model_obj = xgb.XGBRegressor(
                            n_estimators=n_estimators or 400,
                            max_depth=max_depth or 6,
                            learning_rate=learning_rate or 0.05,
                            subsample=0.9,
                            colsample_bytree=0.9,
                            random_state=random_state,
                            n_jobs=-1,
                        )
                except Exception:
                    # Fallback to RandomForest for portability
                    model_used = "random_forest"
                    if problem_type == "classification":
                        from sklearn.ensemble import RandomForestClassifier
                        model_obj = RandomForestClassifier(
                            n_estimators=n_estimators or 200,
                            max_depth=max_depth,
                            random_state=random_state,
                            n_jobs=-1,
                        )
                    else:
                        from sklearn.ensemble import RandomForestRegressor
                        model_obj = RandomForestRegressor(
                            n_estimators=n_estimators or 300,
                            max_depth=max_depth,
                            random_state=random_state,
                            n_jobs=-1,
                        )

            else:
                return f"Model '{model}' is not supported. Options: {SUPPORTED_MODELS}"

            # Train
            model_obj.fit(X_train, y_train)

            # Metrics
            metrics: Dict[str, Any] = {"problem_type": problem_type, "model": model_used, "target": target_col}
            if problem_type == "classification":
                y_pred = model_obj.predict(X_test)
                # AUC needs probabilities or decision scores
                try:
                    y_proba = model_obj.predict_proba(X_test)
                    if y_proba.shape[1] == 2:
                        auc = roc_auc_score(y_test, y_proba[:, 1])
                    else:
                        auc = roc_auc_score(y_test, y_proba, multi_class="ovr")
                except Exception:
                    auc = None
                metrics.update({
                    "accuracy": float(accuracy_score(y_test, y_pred)),
                    "precision_macro": float(precision_score(y_test, y_pred, average="macro", zero_division=0)),
                    "recall_macro": float(recall_score(y_test, y_pred, average="macro", zero_division=0)),
                    "f1_macro": float(f1_score(y_test, y_pred, average="macro", zero_division=0)),
                    "roc_auc": (float(auc) if auc is not None else None),
                })
            else:
                y_pred = model_obj.predict(X_test)
                metrics.update({
                    "rmse": float(np.sqrt(mean_squared_error(y_test, y_pred))),
                    "mae": float(mean_absolute_error(y_test, y_pred)),
                    "r2": float(r2_score(y_test, y_pred)),
                })

            # Persist artifacts
            out_dir = _safe_mkdir(artifacts_dir)
            base_name = model_name or f"{model_used}_{problem_type}_{target_col}"
            model_path = os.path.join(out_dir, f"{base_name}.joblib")
            metrics_path = os.path.join(out_dir, f"{base_name}_metrics.json")

            joblib.dump(model_obj, model_path)
            _dump_json(metrics_path, metrics)

            # Concise report
            header = [
                f"Model trained: {model_used}",
                f"Problem: {problem_type}",
                f"Target: {target_col}",
                f"Train/Test split: {1 - test_size:.2f}/{test_size:.2f} (random_state={random_state})",
                f"Artifacts: model -> {model_path}, metrics -> {metrics_path}",
                "KEY METRICS:",
            ]
            lines = [*header]
            for k, v in metrics.items():
                if k in {"problem_type", "model", "target"}:
                    continue
                lines.append(f"- {k}: {v}")
            report = "\n".join(lines)  # usar saltos para legibilidad
            CTX.add_decision("training", f"Trained {model_used} ({problem_type}) target={target_col}")
            return report

        except Exception as e:
            return f"ModelTrainingTool failed: {type(e).__name__}: {e}"

