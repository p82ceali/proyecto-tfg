# coordinator_agent.py (updated to include Model Training Agent) 
from __future__ import annotations
from typing import Type, Optional, List

import os
import pandas as pd
from pydantic import BaseModel, Field

from crewai import Agent, Task, Crew, LLM
from crewai.tools import BaseTool
from dotenv import load_dotenv


# === Relative imports (keep your current package layout) ===
from . import analysis_agent as analysis
from . import preprocessing_agent as preprocessing
from . import feature_selection_agent as fsel
from . import instance_selection_agent as isel
from . import model_training_agent as mtrain 

# ---------------------------------------------------------------------
# LLM setup
# ---------------------------------------------------------------------
load_dotenv()
llm = LLM(
    model="gemini/gemini-2.0-flash-lite",
    api_key=os.getenv("GOOGLE_API_KEY"),
    custom_llm_provider="gemini",
)

# ---------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------
def _attach_dataset_to_agent_tools(agent: Agent, df: pd.DataFrame) -> None:
    """Attach the same pandas DataFrame instance to every tool on an agent."""
    for t in getattr(agent, "tools", []):
        t.dataset = df


# ---------------------------------------------------------------------
# Structured input shared by delegates
# ---------------------------------------------------------------------
class DelegateInput(BaseModel):
    user_request: str = Field(..., description="Raw user request to forward to the chosen subâ€‘agent.")
    chat_context: Optional[str] = Field("", description="Window of chat history.")


# ---------------------------------------------------------------------
# Delegates
# ---------------------------------------------------------------------
class DelegateToAnalysisTool(BaseTool):
    name: str = "delegate_to_analysis"
    description: str = (
        "Delegate to the Analysis Agent (describe feature, mean/median/mode, grouped stats, etc.). "
        "Input must include {'user_request': <text>}."
    )
    args_schema: Type[BaseModel] = DelegateInput
    dataset: Type[pd.DataFrame] = None

    def _run(self, user_request: str, chat_context: str = "") -> str:
        if not hasattr(self, "dataset") or not isinstance(self.dataset, pd.DataFrame):
            return "No dataset attached to analysis delegate. Attach a DataFrame via tool.dataset = df."
        sub_agent = analysis.build_agent()
        print('\n', '*'*30, '\n', 'COORDINATOR: delegating to ANALYSIS', '\n', '*'*30)
        _attach_dataset_to_agent_tools(sub_agent, self.dataset)
        sub_task = analysis.build_task(sub_agent)
        sub_crew = Crew(agents=[sub_agent], tasks=[sub_task], verbose=False)
        result = sub_crew.kickoff(inputs={
            "user_request": user_request,
            "chat_context": chat_context,  # <-- PROPAGADO
        })
        return "ðŸ”€ Route: ANALYSIS\n" + str(result)


class DelegateToPreprocessingTool(BaseTool):
    name: str = "delegate_to_preprocessing"
    description: str = (
        "Delegate to the Preprocessing Agent (discretization/binning, oneâ€‘hot encoding, etc.). "
        "Input must include {'user_request': <text>}."
    )
    args_schema: Type[BaseModel] = DelegateInput
    dataset: Type[pd.DataFrame] = None
    autosave_path: Optional[str] = "pipeline_data/dataset.csv"

    def _run(self, user_request: str, chat_context: str = "") -> str:
        if not hasattr(self, "dataset") or not isinstance(self.dataset, pd.DataFrame):
            return "No dataset attached to preprocessing delegate. Attach a DataFrame via tool.dataset = df."
        sub_agent = preprocessing.build_preprocessing_agent()
        print('\n', '*'*30, '\n', 'COORDINATOR: delegating to PREPROCESSING', '\n', '*'*30)
        _attach_dataset_to_agent_tools(sub_agent, self.dataset)
        sub_task = preprocessing.build_task(sub_agent)
        sub_crew = Crew(agents=[sub_agent], tasks=[sub_task], verbose=False)
        result = sub_crew.kickoff(inputs={
            "user_request": user_request,
            "chat_context": chat_context,  # <-- PROPAGADO
        })

        if self.autosave_path:
            try:
                os.makedirs(os.path.dirname(self.autosave_path), exist_ok=True)
                self.dataset.to_csv(self.autosave_path, index=False)
                result = str(result) + f"\n\nðŸ’¾ Saved changes to {self.autosave_path}"
            except Exception as se:
                result = str(result) + f"\n\nâš ï¸ Failed to save dataset: {se}"

        return "ðŸ”€ Route: PREPROCESSING\n" + str(result)


class DelegateToFeatureSelectionTool(BaseTool):
    name: str = "delegate_to_feature_selection"
    description: str = (
        "Delegate to the Feature Selection Agent (kâ€‘best, variance/correlation filters, RF importances, etc.). "
        "Input must include {'user_request': <text>}."
    )
    args_schema: Type[BaseModel] = DelegateInput
    dataset: Type[pd.DataFrame] = None
    autosave_path: Optional[str] = "pipeline_data/dataset.csv"

    def _run(self, user_request: str, chat_context: str = "") -> str:
        if not hasattr(self, "dataset") or not isinstance(self.dataset, pd.DataFrame):
            return "No dataset attached to featureâ€‘selection delegate. Attach a DataFrame via tool.dataset = df."
        sub_agent = fsel.build_agent()
        print('\n', '*'*30, '\n', 'COORDINATOR: delegating to FEATURE_SELECTION', '\n', '*'*30)
        _attach_dataset_to_agent_tools(sub_agent, self.dataset)
        sub_task = fsel.build_task(sub_agent)
        sub_crew = Crew(agents=[sub_agent], tasks=[sub_task], verbose=False)
        result = sub_crew.kickoff(inputs={
            "user_request": user_request,
            "chat_context": chat_context,  # <-- PROPAGADO
        })

        if self.autosave_path:
            try:
                os.makedirs(os.path.dirname(self.autosave_path), exist_ok=True)
                self.dataset.to_csv(self.autosave_path, index=False)
                result = str(result) + f"\n\nðŸ’¾ Saved changes to {self.autosave_path}"
            except Exception as se:
                result = str(result) + f"\n\nâš ï¸ Failed to save dataset: {se}"

        return "ðŸ”€ Route: FEATURE_SELECTION\n" + str(result)


class DelegateToInstanceSelectionTool(BaseTool):
    name: str = "delegate_to_instance_selection"
    description: str = (
        "Delegate to the Instance Selection Agent (stratified/random/classâ€‘balanced/clustered sampling, "
        "or dataset splits train/val/test, timeâ€‘series split). Input must include {'user_request': <text>}."
    )
    args_schema: Type[BaseModel] = DelegateInput
    dataset: Type[pd.DataFrame] = None
    autosave_path: Optional[str] = "pipeline_data/dataset.csv"

    def _run(self, user_request: str, chat_context: str = "") -> str:
        if not hasattr(self, "dataset") or not isinstance(self.dataset, pd.DataFrame):
            return "No dataset attached to instanceâ€‘selection delegate. Attach a DataFrame via tool.dataset = df."
        sub_agent = isel.build_agent()
        print('\n', '*'*30, '\n', 'COORDINATOR: delegating to INSTANCE_SELECTION', '\n', '*'*30)
        _attach_dataset_to_agent_tools(sub_agent, self.dataset)
        sub_task = isel.build_task(sub_agent)
        sub_crew = Crew(agents=[sub_agent], tasks=[sub_task], verbose=False)
        result = sub_crew.kickoff(inputs={
            "user_request": user_request,
            "chat_context": chat_context,  # <-- PROPAGADO
        })

        if self.autosave_path:
            try:
                os.makedirs(os.path.dirname(self.autosave_path), exist_ok=True)
                self.dataset.to_csv(self.autosave_path, index=False)
                result = str(result) + f"\n\nðŸ’¾ Saved working dataset to {self.autosave_path}"
            except Exception as se:
                result = str(result) + f"\n\nâš ï¸ Failed to save dataset: {se}"

        return "ðŸ”€ Route: INSTANCE_SELECTION\n" + str(result)


# ------------------------- NEW: Model Training delegate -------------------------
class DelegateToModelTrainingTool(BaseTool):
    name: str = "delegate_to_model_training"
    description: str = (
        "Delegate to the Model Training Agent (model selection, training, metrics, and artifact persistence). "
        "Input must include {'user_request': <text>}."
    )
    args_schema: Type[BaseModel] = DelegateInput
    dataset: Type[pd.DataFrame] = None
    artifacts_dir: Optional[str] = "pipeline_data/artifacts"

    def _run(self, user_request: str, chat_context: str = "") -> str:
        if not hasattr(self, "dataset") or not isinstance(self.dataset, pd.DataFrame):
            return "No dataset attached to modelâ€‘training delegate. Attach a DataFrame via tool.dataset = df."

        sub_agent = mtrain.build_model_training_agent()
        print('\n', '*'*30, '\n', 'COORDINATOR: delegating to MODEL_TRAINING', '\n', '*'*30)
        _attach_dataset_to_agent_tools(sub_agent, self.dataset)
        sub_task = mtrain.build_task(sub_agent)
        sub_crew = Crew(agents=[sub_agent], tasks=[sub_task], verbose=False)
        result = sub_crew.kickoff(inputs={
            "user_request": user_request,
            "chat_context": chat_context,  # <-- PROPAGADO
        })
        return "ðŸ”€ Route: MODEL_TRAINING\n" + str(result)


# ---------------------------------------------------------------------
# Coordinator agent + task
# ---------------------------------------------------------------------
def build_coordinator_agent(df: pd.DataFrame) -> Agent:
    """Create a coordinator with delegate tools and attach the dataset to all delegates."""
    delegates: List[BaseTool] = [
        DelegateToAnalysisTool(),
        DelegateToPreprocessingTool(),
        DelegateToFeatureSelectionTool(),
        DelegateToInstanceSelectionTool(),
        DelegateToModelTrainingTool(),  # <-- NEW
    ]
    for t in delegates:
        t.dataset = df

    return Agent(
        role="Coordinator",
        goal=(
            "Read the user's request and decide whether it is an ANALYSIS request, a PREPROCESSING request, "
            "a FEATURE SELECTION request, an INSTANCE SELECTION/SPLITTING request, or a MODEL TRAINING request. "
            "Call exactly ONE delegate tool with the original user_request and return its result verbatim."
        ),
        backstory=(
            "You are a precise orchestrator. You never compute yourself; you delegate to the most relevant specialist "
            "and deliver their answer."
        ),
        tools=delegates,
        verbose=True,
        llm=llm,
    )


def build_coordinator_task(agent: Agent) -> Task:
    return Task(
        description=(
            "CONVERSATION CONTEXT (last turns):\n{chat_context}\n\n"
            "User request: {user_request}\n\n"
            "Decide:\n"
            "- If DESCRIPTIVE ANALYSIS or stats: call delegate_to_analysis.\n"
            "- If PREPROCESSING (discretization/binning, oneâ€‘hot): call delegate_to_preprocessing.\n"
            "- If FEATURE SELECTION (kâ€‘best, filters, importances): call delegate_to_feature_selection.\n"
            "- If INSTANCE SELECTION / SPLITTING (sampling/splits): call delegate_to_instance_selection.\n"
            "- If MODEL TRAINING (choose/train/evaluate/persist): call delegate_to_model_training.\n\n"
            "Call exactly ONE delegate tool and return the subâ€‘agent's result. If the request is ambiguous, "
            "ask one short clarifying question and stop."
        ),
        expected_output="Either the subâ€‘agent's final answer or one short clarifying question.",
        agent=agent,
    )


